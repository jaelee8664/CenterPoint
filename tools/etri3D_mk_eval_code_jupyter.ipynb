{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목적: visualize 및 평가 metric 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no apex\n",
      "No Tensorflow\n",
      "Deformable Convolution not built!\n",
      "No APEX!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning, NumbaWarning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaWarning)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from det3d import torchie\n",
    "from det3d.datasets import build_dataloader, build_dataset\n",
    "from det3d.models import build_detector\n",
    "from det3d.torchie import Config\n",
    "from det3d.torchie.apis import (\n",
    "    batch_processor,\n",
    "    build_optimizer,\n",
    "    get_root_logger,\n",
    "    init_dist,\n",
    "    set_random_seed,\n",
    "    train_detector,\n",
    ")\n",
    "from det3d.torchie.trainer import load_checkpoint\n",
    "import torch.distributed as dist\n",
    "import subprocess\n",
    "\n",
    "# 주피터 노트북 경로설정\n",
    "os.chdir('../')\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Train a detector\")\n",
    "    parser.add_argument(\"--config\", default=\"configs/etriInfra/pp/etriInfra_centerpoint_pp_02voxel_two_pfn_10sweep.py\", help=\"train config file path\")\n",
    "    parser.add_argument(\"--work_dir\", help=\"the dir to save logs and models\")\n",
    "    parser.add_argument(\"--resume_from\", help=\"the checkpoint file to resume from\")\n",
    "    parser.add_argument(\n",
    "        \"--validate\",\n",
    "        action=\"store_true\",\n",
    "        help=\"whether to evaluate the checkpoint during training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gpus\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"number of gpus to use \" \"(only applicable to non-distributed training)\",\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", type=int, default=None, help=\"random seed\")\n",
    "    parser.add_argument(\n",
    "        \"--launcher\",\n",
    "        choices=[\"pytorch\", \"slurm\"],\n",
    "        default=\"pytorch\",\n",
    "        help=\"job launcher\",\n",
    "    )\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "    parser.add_argument(\n",
    "        \"--autoscale-lr\",\n",
    "        action=\"store_true\",\n",
    "        help=\"automatically scale lr with the number of gpus\",\n",
    "    )\n",
    "    args = parser.parse_args(args=[])\n",
    "    if \"LOCAL_RANK\" not in os.environ:\n",
    "        os.environ[\"LOCAL_RANK\"] = str(args.local_rank)\n",
    "\n",
    "    return args\n",
    "args = parse_args()\n",
    "cfg = Config.fromfile(args.config)\n",
    "# distribution 설정 안함\n",
    "cfg.local_rank = args.local_rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 15:07:51,924 - INFO - Distributed training: False\n",
      "2024-04-12 15:07:51,925 - INFO - torch.backends.cudnn.benchmark: False\n"
     ]
    }
   ],
   "source": [
    "# init logger before other steps\n",
    "distributed = False\n",
    "cfg.gpus = args.gpus\n",
    "logger = get_root_logger(cfg.log_level)\n",
    "logger.info(\"Distributed training: {}\".format(distributed))\n",
    "logger.info(f\"torch.backends.cudnn.benchmark: {torch.backends.cudnn.benchmark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 15:07:52,260 - INFO - Finish RPN Initialization\n",
      "2024-04-12 15:07:52,260 - INFO - num_classes: [2, 2, 1, 1, 2, 1]\n",
      "2024-04-12 15:07:52,278 - INFO - Finish CenterHead Initialization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use HM Bias:  -2.19\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.testset = False\n",
    "dataset = build_dataset(cfg.data.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.speed_test = True\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        batch_size=cfg.data.samples_per_gpu if not args.speed_test else 1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=distributed,\n",
    "        shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.checkpoint = \"modelzoo/etri3D_pointpillar/etri3D_latest.pth\"\n",
    "checkpoint = load_checkpoint(model, args.checkpoint, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "model.eval()\n",
    "mode = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 15:07:54,719 - INFO - work dir: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                              ] 0/3000, elapsed: 0s, ETA:"
     ]
    }
   ],
   "source": [
    "logger.info(f\"work dir: {args.work_dir}\")\n",
    "if cfg.local_rank == 0:\n",
    "    prog_bar = torchie.ProgressBar(len(data_loader.dataset) // cfg.gpus)\n",
    "\n",
    "detections = {}\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "start = int(len(dataset) / 3)\n",
    "end = int(len(dataset) * 2 /3)\n",
    "\n",
    "time_start = 0 \n",
    "time_end = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "/home/jaelee/anaconda3/envs/centerpoint/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "for i, data_batch in enumerate(data_loader):\n",
    "    if i == start:\n",
    "        torch.cuda.synchronize()\n",
    "        time_start = time.time()\n",
    "\n",
    "    if i == end:\n",
    "        torch.cuda.synchronize()\n",
    "        time_end = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = batch_processor(\n",
    "            model, data_batch, train_mode=False, local_rank=args.local_rank,\n",
    "        )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': [{'image_prefix': PosixPath('data/etri3Dobj_infra_edge'),\n",
       "   'num_point_features': 3}],\n",
       " 'points': [tensor([[-2.9951e-04,  1.4299e-01,  3.8175e-02],\n",
       "          [ 1.2478e-04,  1.4299e-01,  3.8175e-02],\n",
       "          [ 6.2054e-04,  1.5458e-01,  4.1271e-02],\n",
       "          ...,\n",
       "          [-1.7872e-03,  1.3837e-01, -3.9827e-02],\n",
       "          [-1.3901e-03,  1.4222e-01, -4.0933e-02],\n",
       "          [-8.9228e-04,  1.3454e-01, -3.8721e-02]])],\n",
       " 'voxels': tensor([[[-2.9951e-04,  1.4299e-01,  3.8175e-02],\n",
       "          [-6.0129e-02,  1.9175e-01,  5.3652e-02],\n",
       "          [-6.1816e-02,  1.9933e-01,  5.5716e-02],\n",
       "          ...,\n",
       "          [-3.8855e-02,  1.6951e-01,  4.6430e-02],\n",
       "          [-3.7470e-02,  1.6586e-01,  4.5398e-02],\n",
       "          [-3.1911e-02,  1.4335e-01,  3.9207e-02]],\n",
       " \n",
       "         [[ 1.2478e-04,  1.4299e-01,  3.8175e-02],\n",
       "          [ 6.2054e-04,  1.5458e-01,  4.1271e-02],\n",
       "          [ 1.1891e-03,  1.6618e-01,  4.4366e-02],\n",
       "          ...,\n",
       "          [ 9.0158e-03,  1.6593e-01,  4.4366e-02],\n",
       "          [ 9.5370e-03,  1.6591e-01,  4.4366e-02],\n",
       "          [ 9.5903e-03,  1.5816e-01,  4.2303e-02]],\n",
       " \n",
       "         [[ 1.0874e+00,  1.0059e+01,  2.7012e+00],\n",
       "          [ 1.0991e+00,  1.0167e+01,  2.5371e+00],\n",
       "          [ 1.1263e+00,  1.0121e+01,  2.5265e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.7852e+00,  1.6106e+00, -9.2598e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[-2.4512e+00,  1.9878e+00, -9.0828e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[-2.0977e+00,  2.5996e+00, -9.6138e-01],\n",
       "          [-2.0001e+00,  2.5934e+00, -9.4257e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]),\n",
       " 'shape': array([[512, 512,   1]]),\n",
       " 'num_points': tensor([20, 20,  8,  ...,  1,  1,  2], dtype=torch.int32),\n",
       " 'num_voxels': tensor([8598]),\n",
       " 'coordinates': tensor([[  0,   0, 256, 255],\n",
       "         [  0,   0, 256, 256],\n",
       "         [  0,   0, 306, 261],\n",
       "         ...,\n",
       "         [  0,   0, 264, 242],\n",
       "         [  0,   0, 265, 243],\n",
       "         [  0,   0, 268, 245]], dtype=torch.int32),\n",
       " 'anno_box': [tensor([[[-1.2137e+01, -4.1630e+01, -1.0651e+00,  1.8684e+00,  3.5237e+00,\n",
       "             1.5000e+00,  0.0000e+00,  0.0000e+00,  2.7520e+00],\n",
       "           [ 3.9365e+01,  3.2629e+01, -1.0084e+00,  2.1836e+00,  4.7132e+00,\n",
       "             1.7017e+00,  0.0000e+00,  0.0000e+00, -2.2873e+00],\n",
       "           [ 4.3291e+01,  3.2019e+01, -1.1456e+00,  2.1430e+00,  4.7571e+00,\n",
       "             1.5000e+00,  0.0000e+00,  0.0000e+00, -2.2439e+00],\n",
       "           [-2.6418e+01,  4.0977e+00,  5.0232e-01,  2.1176e+00,  4.2946e+00,\n",
       "             1.9041e+00,  0.0000e+00,  0.0000e+00, -4.0526e-01],\n",
       "           [-2.4271e+01, -6.3866e+00, -4.5998e-01,  2.0639e+00,  4.8000e+00,\n",
       "             1.4675e+00,  0.0000e+00,  0.0000e+00, -4.3944e-01],\n",
       "           [-3.0731e+01, -5.4525e-02,  1.6352e-01,  2.1337e+00,  4.0709e+00,\n",
       "             1.5520e+00,  0.0000e+00,  0.0000e+00, -3.2496e-01],\n",
       "           [-3.3297e+01, -2.6228e+00,  2.7764e-02,  2.1313e+00,  4.6480e+00,\n",
       "             1.6065e+00,  0.0000e+00,  0.0000e+00, -2.9202e-01],\n",
       "           [ 8.5784e+00, -1.4461e+01, -9.7246e-01,  2.2441e+00,  4.5236e+00,\n",
       "             1.7000e+00,  0.0000e+00,  0.0000e+00, -2.3109e+00],\n",
       "           [-2.0545e+01, -4.2907e+00, -5.6195e-01,  2.2382e+00,  4.6586e+00,\n",
       "             1.6493e+00,  0.0000e+00,  0.0000e+00, -4.5717e-01]]],\n",
       "         dtype=torch.float64),\n",
       "  tensor([], size=(1, 0, 9), dtype=torch.float64),\n",
       "  tensor([], size=(1, 0, 9), dtype=torch.float64),\n",
       "  tensor([], size=(1, 0, 9), dtype=torch.float64),\n",
       "  tensor([], size=(1, 0, 9), dtype=torch.float64),\n",
       "  tensor([], size=(1, 0, 9), dtype=torch.float64)],\n",
       " 'anno_cls': array([[array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       "         array([], dtype=int32), array([], dtype=int32),\n",
       "         array([], dtype=int32), array([], dtype=int32),\n",
       "         array([], dtype=int32)]], dtype=object)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_batch['anno_box'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       "        array([], dtype=int32), array([], dtype=int32),\n",
       "        array([], dtype=int32), array([], dtype=int32),\n",
       "        array([], dtype=int32)]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch['anno_cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]['box3d_lidar'].cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'box3d_lidar': tensor([[-2.0572e+01, -4.2772e+00, -5.6578e-01,  2.2512e+00,  4.6266e+00,\n",
       "           1.6879e+00, -4.4454e-01],\n",
       "         [-3.3328e+01, -2.6246e+00,  4.1864e-03,  2.1117e+00,  4.5908e+00,\n",
       "           1.6341e+00, -2.8629e-01],\n",
       "         [-3.0738e+01, -7.5428e-02,  1.4909e-01,  2.1568e+00,  4.0811e+00,\n",
       "           1.5518e+00, -2.6346e-01],\n",
       "         [-2.4313e+01, -6.4297e+00, -4.5093e-01,  2.0369e+00,  4.7302e+00,\n",
       "           1.4803e+00, -4.8538e-01],\n",
       "         [ 8.5508e+00, -1.4463e+01, -1.0313e+00,  2.1285e+00,  4.5201e+00,\n",
       "           1.6315e+00, -2.3890e+00],\n",
       "         [-2.6394e+01,  4.1298e+00,  4.9087e-01,  2.1077e+00,  4.3319e+00,\n",
       "           1.9290e+00, -3.8688e-01],\n",
       "         [ 4.3494e+01,  3.2174e+01, -1.2120e+00,  2.1740e+00,  5.3026e+00,\n",
       "           1.7410e+00, -2.3136e+00],\n",
       "         [-1.1879e+01, -4.1863e+01, -9.8651e-01,  2.1246e+00,  4.1871e+00,\n",
       "           1.6877e+00,  2.7386e+00],\n",
       "         [-2.3597e+01, -1.3271e+01, -8.2382e-01,  6.0167e-01,  1.4842e+00,\n",
       "           1.4185e+00,  2.5586e+00],\n",
       "         [ 4.3627e+01,  3.2375e+01, -9.6377e-01,  2.1149e+00,  5.2301e+00,\n",
       "           1.9968e+00, -2.4051e+00],\n",
       "         [ 3.8796e-01, -5.1741e+01, -1.0652e+00,  9.5388e-01,  2.5635e+00,\n",
       "           1.6041e+00,  2.3395e+00],\n",
       "         [-3.1782e-01, -4.9142e+01, -1.1312e+00,  9.7344e-01,  2.5063e+00,\n",
       "           1.6100e+00,  2.2420e+00],\n",
       "         [-3.4394e-01, -5.0010e+01, -1.0722e+00,  9.9579e-01,  2.5658e+00,\n",
       "           1.6219e+00,  2.1127e+00],\n",
       "         [-3.4267e-01, -4.8363e+01, -1.1489e+00,  9.6935e-01,  2.5119e+00,\n",
       "           1.5937e+00,  2.3628e+00],\n",
       "         [-1.1233e+00, -5.1751e+01, -1.2154e+00,  9.8090e-01,  2.5346e+00,\n",
       "           1.7608e+00,  1.5385e+00]], device='cuda:0'),\n",
       " 'scores': tensor([0.9743, 0.9651, 0.9557, 0.8024, 0.7886, 0.7080, 0.6653, 0.5122, 0.3202,\n",
       "         0.1387, 0.2062, 0.1142, 0.1135, 0.1059, 0.1030], device='cuda:0'),\n",
       " 'label_preds': tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 6, 6, 6, 6, 7], device='cuda:0'),\n",
       " 'metadata': {'image_prefix': PosixPath('data/etri3Dobj_infra_edge'),\n",
       "  'num_point_features': 3}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box3d_lidar\n",
      "scores\n",
      "label_preds\n",
      "metadata\n"
     ]
    }
   ],
   "source": [
    "output = outputs[0]\n",
    "for k, v in output.items():\n",
    "    print(f\"{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = []\n",
    "for k, v in output.items():\n",
    "    if k not in [\n",
    "        \"metadata\",\n",
    "    ]:\n",
    "        output[k] = v.to(cpu_device)\n",
    "    detections.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.0572489e+01, -4.2772408e+00, -5.6578290e-01,  2.2511895e+00,\n",
       "         4.6265812e+00,  1.6878871e+00, -4.4454461e-01],\n",
       "       [-3.3327682e+01, -2.6246338e+00,  4.1864216e-03,  2.1116798e+00,\n",
       "         4.5908461e+00,  1.6340932e+00, -2.8629452e-01],\n",
       "       [-3.0738068e+01, -7.5428009e-02,  1.4908600e-01,  2.1568010e+00,\n",
       "         4.0810599e+00,  1.5518138e+00, -2.6345658e-01],\n",
       "       [-2.4312590e+01, -6.4296608e+00, -4.5093194e-01,  2.0368633e+00,\n",
       "         4.7302055e+00,  1.4802680e+00, -4.8537868e-01],\n",
       "       [ 8.5507698e+00, -1.4463158e+01, -1.0312934e+00,  2.1284766e+00,\n",
       "         4.5201240e+00,  1.6314881e+00, -2.3890283e+00],\n",
       "       [-2.6394234e+01,  4.1297989e+00,  4.9087492e-01,  2.1077068e+00,\n",
       "         4.3318663e+00,  1.9290257e+00, -3.8688421e-01],\n",
       "       [ 4.3493717e+01,  3.2173809e+01, -1.2119828e+00,  2.1739845e+00,\n",
       "         5.3026314e+00,  1.7410246e+00, -2.3136003e+00],\n",
       "       [-1.1878700e+01, -4.1862572e+01, -9.8651147e-01,  2.1245551e+00,\n",
       "         4.1870604e+00,  1.6876872e+00,  2.7386403e+00],\n",
       "       [-2.3597342e+01, -1.3270519e+01, -8.2382476e-01,  6.0166836e-01,\n",
       "         1.4842154e+00,  1.4184960e+00,  2.5586085e+00],\n",
       "       [ 4.3626835e+01,  3.2375393e+01, -9.6376747e-01,  2.1148548e+00,\n",
       "         5.2301049e+00,  1.9967862e+00, -2.4051487e+00],\n",
       "       [ 3.8796234e-01, -5.1740528e+01, -1.0652474e+00,  9.5388269e-01,\n",
       "         2.5635357e+00,  1.6041143e+00,  2.3395343e+00],\n",
       "       [-3.1781769e-01, -4.9141632e+01, -1.1311992e+00,  9.7343820e-01,\n",
       "         2.5062521e+00,  1.6100497e+00,  2.2419806e+00],\n",
       "       [-3.4393692e-01, -5.0010010e+01, -1.0722219e+00,  9.9578875e-01,\n",
       "         2.5658050e+00,  1.6219311e+00,  2.1127169e+00],\n",
       "       [-3.4267426e-01, -4.8363377e+01, -1.1489153e+00,  9.6935380e-01,\n",
       "         2.5118716e+00,  1.5937122e+00,  2.3628242e+00],\n",
       "       [-1.1233025e+00, -5.1750980e+01, -1.2153678e+00,  9.8090100e-01,\n",
       "         2.5345836e+00,  1.7607687e+00,  1.5385250e+00]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['box3d_lidar'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 6, 6, 6, 6, 7])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['label_preds'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97432446, 0.9651002 , 0.9556864 , 0.80238724, 0.7886445 ,\n",
       "       0.7079947 , 0.6652666 , 0.51221067, 0.32024455, 0.13874333,\n",
       "       0.2061549 , 0.11421622, 0.11346538, 0.10587288, 0.10296192],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['scores'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.9950603e-04,  1.4299141e-01,  3.8175460e-02],\n",
       "       [ 1.2478379e-04,  1.4299168e-01,  3.8175460e-02],\n",
       "       [ 6.2054489e-04,  1.5458441e-01,  4.1270766e-02],\n",
       "       ...,\n",
       "       [-1.7872249e-03,  1.3837129e-01, -3.9827053e-02],\n",
       "       [-1.3901073e-03,  1.4222001e-01, -4.0933359e-02],\n",
       "       [-8.9227577e-04,  1.3453589e-01, -3.8720746e-02]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch['points'][0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_to_xyz(fp):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    # fp = np.fromfile(fname, dtype=np.float32)\n",
    "    # fp = fp.reshape(-1,3)\n",
    "    for i in range(fp.shape[0]):\n",
    "        x.append(fp[i][0])\n",
    "        y.append(fp[i][1])\n",
    "        z.append(fp[i][2])\n",
    "    return x,y,z\n",
    "\n",
    "def writePCDFile(fname,x,y,z):\n",
    "    numPoints= len(x)\n",
    "    with open(fname, 'w') as fp:\n",
    "        fp.write(\"VERSION 0.7\\n\")\n",
    "        fp.write(\"FIELDS x y z\\n\")\n",
    "        fp.write(\"SIZE 4 4 4\\n\")\n",
    "        fp.write(\"TYPE F F F\\n\")\n",
    "        fp.write(\"WIDTH \"+str(numPoints)+\"\\n\")\n",
    "        fp.write(\"HEIGHT 1\\n\")\n",
    "        fp.write(\"POINTS \"+str(numPoints)+\"\\n\")\n",
    "        fp.write(\"DATA ascii\\n\")\n",
    "        for index in range(numPoints):\n",
    "            txtLine = \"{} {} {}\\n\".format(x[index],y[index],z[index] )\n",
    "            fp.write(txtLine)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = \"/home/jaelee/objdect/CenterPoint/etri3Deval\"\n",
    "x,y,z =pt_to_xyz(data_batch['points'][0].cpu().numpy())\n",
    "idx_p = 0\n",
    "pth = Path(f\"ex{idx_p}\")\n",
    "pcd_name = rt / pth.with_suffix('.pcd')\n",
    "writePCDFile(pcd_name,x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes = output['box3d_lidar'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_3 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3b63b3b84a4bbf8e71ce50c8f24a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_3')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Sending init frames to window_3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4687:067][751005] (stun_port.cc:96): Binding request timed out from 10.42.0.x:51437 (enp5s0)\n",
      "[4687:132][751005] (stun_port.cc:96): Binding request timed out from 10.42.0.x:51437 (enp5s0)\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from open3d.web_visualizer import draw\n",
    "points_v = data_batch[\"points\"][0]\n",
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=2, origin=[0,0,0])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points_v)\n",
    "entities_to_draw = [pcd, mesh_frame]\n",
    "# for idx in range(gt_boxes.shape[0]):\n",
    "# idx = 0\n",
    "for idx in range(len(pred_boxes)):\n",
    "        if output['scores'].cpu().numpy()[idx] <= 0.2:\n",
    "                continue\n",
    "        translation = pred_boxes[idx][:3]\n",
    "        w, l, h = pred_boxes[idx][3], pred_boxes[idx][4], pred_boxes[idx][5]\n",
    "        rotation = pred_boxes[idx][-1]\n",
    "\n",
    "        bounding_box = np.array([\n",
    "                        [-l/2, -l/2, l/2, l/2, -l/2, -l/2, l/2, l/2],\n",
    "                        [w/2, -w/2, -w/2, w/2, w/2, -w/2, -w/2, w/2],\n",
    "                        [-h/2, -h/2, -h/2, -h/2, h/2, h/2, h/2, h/2]]) \n",
    "        rotation_matrix = np.array([\n",
    "                [np.cos(rotation), -np.sin(rotation), 0.0],\n",
    "                [np.sin(rotation), np.cos(rotation), 0.0],\n",
    "                [0.0, 0.0, 1.0]])\n",
    "        eight_points = np.tile(translation, (8, 1))\n",
    "\n",
    "        corner_box = np.dot(rotation_matrix, bounding_box) + eight_points.transpose()\n",
    "        boxes3d_pts = corner_box.transpose()\n",
    "        boxes3d_pts = boxes3d_pts.T\n",
    "        boxes3d_pts = o3d.utility.Vector3dVector(boxes3d_pts.T)\n",
    "        box = o3d.geometry.OrientedBoundingBox.create_from_points(boxes3d_pts)\n",
    "        box.color = [1, 0, 0]           #Box color would be red box.color = [R,G,B]\n",
    "        entities_to_draw.append(box)\n",
    "draw([*entities_to_draw])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_2 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdf1976a26d48edbef68311f6af9700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_2')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Sending init frames to window_2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[334:119][751005] (stun_port.cc:96): Binding request timed out from 10.42.0.x:38251 (enp5s0)\n",
      "[334:219][751005] (stun_port.cc:96): Binding request timed out from 10.42.0.x:38251 (enp5s0)\n",
      "[352:797][751005] (stun_port.cc:96): Binding request timed out from 10.42.0.x:34992 (enp5s0)\n",
      "[352:798][751005] (stun_port.cc:96): Binding request timed out from 10.42.0.x:34992 (enp5s0)\n"
     ]
    }
   ],
   "source": [
    "gt_boxes = []\n",
    "for ts in data_batch['anno_box']:\n",
    "    ts = ts[0]\n",
    "    gt_boxes.extend(ts.cpu().numpy())\n",
    "points_v = data_batch[\"points\"][0]\n",
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=2, origin=[0,0,0])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points_v)\n",
    "entities_to_draw = [pcd, mesh_frame]\n",
    "# for idx in range(gt_boxes.shape[0]):\n",
    "# idx = 0\n",
    "for idx in range(len(gt_boxes)):\n",
    "        translation = gt_boxes[idx][:3]\n",
    "        w, l, h = gt_boxes[idx][3], gt_boxes[idx][4], gt_boxes[idx][5]\n",
    "        rotation = gt_boxes[idx][-1]\n",
    "\n",
    "        bounding_box = np.array([\n",
    "                        [-l/2, -l/2, l/2, l/2, -l/2, -l/2, l/2, l/2],\n",
    "                        [w/2, -w/2, -w/2, w/2, w/2, -w/2, -w/2, w/2],\n",
    "                        [-h/2, -h/2, -h/2, -h/2, h/2, h/2, h/2, h/2]]) \n",
    "        rotation_matrix = np.array([\n",
    "                [np.cos(rotation), -np.sin(rotation), 0.0],\n",
    "                [np.sin(rotation), np.cos(rotation), 0.0],\n",
    "                [0.0, 0.0, 1.0]])\n",
    "        eight_points = np.tile(translation, (8, 1))\n",
    "\n",
    "        corner_box = np.dot(rotation_matrix, bounding_box) + eight_points.transpose()\n",
    "        boxes3d_pts = corner_box.transpose()\n",
    "        boxes3d_pts = boxes3d_pts.T\n",
    "        boxes3d_pts = o3d.utility.Vector3dVector(boxes3d_pts.T)\n",
    "        box = o3d.geometry.OrientedBoundingBox.create_from_points(boxes3d_pts)\n",
    "        box.color = [0, 1, 0]           #Box color would be red box.color = [R,G,B]\n",
    "        entities_to_draw.append(box)\n",
    "draw([*entities_to_draw])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_class': 2, 'class_names': ['car', 'personal_mobility']},\n",
       " {'num_class': 2, 'class_names': ['truck', 'construction_vehicle']},\n",
       " {'num_class': 1, 'class_names': ['bus']},\n",
       " {'num_class': 1, 'class_names': ['ground_animal']},\n",
       " {'num_class': 2, 'class_names': ['motorcycle', 'bicycle']},\n",
       " {'num_class': 1, 'class_names': ['pedestrian']}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       "        array([], dtype=int32), array([], dtype=int32),\n",
       "        array([], dtype=int32), array([], dtype=int32),\n",
       "        array([], dtype=int32)]], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch['anno_cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'car',\n",
       " 1: 'personal_mobility',\n",
       " 2: 'truck',\n",
       " 3: 'construction_vehicle',\n",
       " 4: 'bus',\n",
       " 5: 'ground_animal',\n",
       " 6: 'motorcycle',\n",
       " 7: 'bicycle',\n",
       " 8: 'pedestrian'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cls_int2name: cls 고유번호에서 이름으로 변환하는 딕셔너리\n",
    "cls_int2name = {}\n",
    "idx = 0\n",
    "for i in range(len(cfg.tasks)):\n",
    "    head_classes = cfg.tasks[i]\n",
    "    class_names = head_classes['class_names']\n",
    "    for j, name in enumerate(class_names):\n",
    "        cls_int2name[idx+j] = name\n",
    "    idx += len(class_names)\n",
    "cls_int2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       "       array([], dtype=int32), array([], dtype=int32),\n",
       "       array([], dtype=int32), array([], dtype=int32),\n",
       "       array([], dtype=int32)], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch['anno_cls'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_batch['anno_cls'] 변환\n",
    "input_cls_id = []\n",
    "idx = 0\n",
    "for i in range(data_batch['anno_cls'][0].shape[0]):\n",
    "    head_classes = cfg.tasks[i]\n",
    "    class_names = head_classes['class_names']\n",
    "    head_class_ids = data_batch['anno_cls'][0][i]\n",
    "    for j in range(len(head_class_ids)):\n",
    "        _id = head_class_ids[j] - 1\n",
    "        input_cls_id.append(idx+_id)\n",
    "    idx += len(class_names)\n",
    "input_cls_id = np.array(input_cls_id)\n",
    "input_cls_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     class_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m     results_dict[single_class] \u001b[38;5;241m=\u001b[39m class_dict\n\u001b[0;32m---> 19\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# self.evaluate(pred_label_path, gt_label_path, label_format)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# file_parsing: class_id, x, y, z, l, w, h, r 순으로 배열 구성\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moutput_to_evalform\u001b[39m(cls_array, box_array, pred_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# class_id, x, y, z, l, w, h, r 순으로 배열 구성\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'time'"
     ]
    }
   ],
   "source": [
    "distance_threshold = 1.0\n",
    "save_loc = 'work_dirs/'\n",
    "distance_threshold_sq = distance_threshold**2\n",
    "score_threshold = min_score = 0.0\n",
    "max_range = max_range = 0.0\n",
    "classes = [v for v in cls_int2name.values()]\n",
    "total_N_pos = 0\n",
    "results_dict = {}\n",
    "for single_class in classes:\n",
    "    class_dict = {}\n",
    "    class_dict['class'] = single_class\n",
    "    class_dict['T_p'] = np.empty((0, 8))\n",
    "    class_dict['gt'] = np.empty((0, 7))\n",
    "    class_dict['total_N_pos'] = 0\n",
    "    class_dict['result'] = np.empty((0, 2))\n",
    "    class_dict['precision'] = []\n",
    "    class_dict['recall'] = []\n",
    "    results_dict[single_class] = class_dict\n",
    "time = time.time()\n",
    "# self.evaluate(pred_label_path, gt_label_path, label_format)\n",
    "# file_parsing: class_id, x, y, z, l, w, h, r 순으로 배열 구성\n",
    "\n",
    "def output_to_evalform(cls_array, box_array, pred_score = None):\n",
    "    # class_id, x, y, z, l, w, h, r 순으로 배열 구성\n",
    "    N = cls_array.shape[0]\n",
    "    if pred_score is not None:\n",
    "        o_ary = np.zeros((N, 9))\n",
    "    else:\n",
    "        o_ary = np.zeros((N, 8))\n",
    "    for i in range(N):\n",
    "        o_ary[i][0] = cls_array[i]\n",
    "        o_ary[i][1] = box_array[i][0]\n",
    "        o_ary[i][2] = box_array[i][1]\n",
    "        o_ary[i][3] = box_array[i][2]\n",
    "        o_ary[i][4] = box_array[i][4]\n",
    "        o_ary[i][5] = box_array[i][3]\n",
    "        o_ary[i][6] = box_array[i][5]\n",
    "        o_ary[i][7] = box_array[i][-1]\n",
    "        if pred_score is not None:\n",
    "            o_ary[i][8] = pred_score[i]\n",
    "    return o_ary\n",
    "predictions = output_to_evalform(output['label_preds'].cpu().numpy(), output['box3d_lidar'].cpu().numpy(), output['scores'].cpu().numpy())\n",
    "ground_truth = output_to_evalform(input_cls_id, np.stack(gt_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_750375/3514758787.py:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  pred_label = pred_label[pred_label[:, 8].astype(np.float) > score_threshold, :]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'class_gt_label' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m         results_dict[single_class][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((results_dict[single_class][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m], result_score_pair))\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_dict\n\u001b[0;32m---> 62\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m \u001b[43meval_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[78], line 46\u001b[0m, in \u001b[0;36meval_pair\u001b[0;34m(pred_label, gt_label, results_dict)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m single_class \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# get all pred labels, order by score\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     class_pred_label \u001b[38;5;241m=\u001b[39m pred_label[np\u001b[38;5;241m.\u001b[39mchar\u001b[38;5;241m.\u001b[39mlower(pred_label[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)) \u001b[38;5;241m==\u001b[39m single_class, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(class_pred_label, \u001b[43mclass_gt_label\u001b[49m)\n\u001b[1;32m     47\u001b[0m     score \u001b[38;5;241m=\u001b[39m class_pred_label[:, \u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     48\u001b[0m     class_pred_label \u001b[38;5;241m=\u001b[39m class_pred_label[(\u001b[38;5;241m-\u001b[39mscore)\u001b[38;5;241m.\u001b[39margsort(), :]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat) \u001b[38;5;66;03m# sort decreasing\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'class_gt_label' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def match_pairs(pred_label, gt_label):\n",
    "    true_preds = np.empty((0, 8))\n",
    "    corresponding_gt = np.empty((0, 7))\n",
    "    result_score = np.empty((0, 2))\n",
    "    # Initialize matching loop\n",
    "    match_incomplete = True\n",
    "    while match_incomplete and gt_label.shape[0] > 0:\n",
    "        match_incomplete = False\n",
    "        for gt_idx, single_gt_label in enumerate(gt_label):\n",
    "            # Check is any prediction is in range\n",
    "            distance_sq_array = (single_gt_label[0] - pred_label[:, 0])**2 + (single_gt_label[1] - pred_label[:, 1])**2\n",
    "            # If there is a prediction in range, pick closest\n",
    "            if np.any(distance_sq_array < distance_threshold_sq):\n",
    "                min_idx = np.argmin(distance_sq_array)\n",
    "                # Store true prediction\n",
    "                true_preds = np.vstack((true_preds, pred_label[min_idx, :].reshape(-1, 1).T))\n",
    "                corresponding_gt = np.vstack((corresponding_gt, gt_label[gt_idx]))\n",
    "\n",
    "                # Store score for mAP\n",
    "                result_score = np.vstack((result_score, np.array([[1, pred_label[min_idx, 7]]])))\n",
    "\n",
    "                # Remove prediction and gt then reset loop\n",
    "                pred_label = np.delete(pred_label, obj=min_idx, axis=0)\n",
    "                gt_label = np.delete(gt_label, obj=gt_idx, axis=0)\n",
    "                match_incomplete = True\n",
    "                break\n",
    "    # If there were any false detections, add them.\n",
    "    if pred_label.shape[0] > 0:\n",
    "        false_positives = np.zeros((pred_label.shape[0], 2))\n",
    "        false_positives[:, 1] = pred_label[:, 7]\n",
    "        result_score = np.vstack((result_score, false_positives))\n",
    "    return true_preds, corresponding_gt, result_score\n",
    "\n",
    "def eval_pair(pred_label, gt_label, results_dict):\n",
    "    ## Check\n",
    "    assert pred_label.shape[1] == 9\n",
    "    assert gt_label.shape[1] == 8\n",
    "\n",
    "    ## Threshold score\n",
    "    if pred_label.shape[0] > 0:\n",
    "        pred_label = pred_label[pred_label[:, 8].astype(np.float) > score_threshold, :]\n",
    "\n",
    "    for single_class in classes:\n",
    "        # get all pred labels, order by score\n",
    "        class_pred_label = pred_label[np.char.lower(pred_label[:, 0].astype(str)) == single_class, 1:]\n",
    "        score = class_pred_label[:, 7].astype(np.float)\n",
    "        class_pred_label = class_pred_label[(-score).argsort(), :].astype(np.float) # sort decreasing\n",
    "\n",
    "        # add gt label length to total_N_pos\n",
    "        class_gt_label = gt_label[np.char.lower(gt_label[:, 0].astype(str)) == single_class, 1:].astype(np.float)\n",
    "        results_dict[single_class]['total_N_pos'] += class_gt_label.shape[0]\n",
    "\n",
    "        # match pairs\n",
    "        pred_array, gt_array, result_score_pair = match_pairs(class_pred_label, class_gt_label)\n",
    "        \n",
    "        # add to existing results\n",
    "        results_dict[single_class]['T_p'] = np.vstack((results_dict[single_class]['T_p'], pred_array))\n",
    "        results_dict[single_class]['gt'] = np.vstack((results_dict[single_class]['gt'], gt_array))\n",
    "        results_dict[single_class]['result'] = np.vstack((results_dict[single_class]['result'], result_score_pair))\n",
    "    return results_dict\n",
    "results_dict = eval_pair(predictions, ground_truth, results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': {'class': 'car',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'personal_mobility': {'class': 'personal_mobility',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'truck': {'class': 'truck',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'construction_vehicle': {'class': 'construction_vehicle',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'bus': {'class': 'bus',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'ground_animal': {'class': 'ground_animal',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'motorcycle': {'class': 'motorcycle',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'bicycle': {'class': 'bicycle',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []},\n",
       " 'pedestrian': {'class': 'pedestrian',\n",
       "  'T_p': array([], shape=(0, 8), dtype=float64),\n",
       "  'gt': array([], shape=(0, 7), dtype=float64),\n",
       "  'total_N_pos': 0,\n",
       "  'result': array([], shape=(0, 2), dtype=float64),\n",
       "  'precision': [],\n",
       "  'recall': []}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처: https://github.com/jacoblambert/3d_lidar_detection_evaluation/blob/master/nuscenes_eval_core.py\n",
    "from label_parser import LabelParser\n",
    "\n",
    "class NuScenesEval:\n",
    "    def __init__(self, pred_label_path, gt_label_path, label_format, save_loc,\n",
    "                 classes=['car', 'pedestrian', 'cyclist'],\n",
    "                 distance_threshold=1.0,\n",
    "                 min_score=0.0,\n",
    "                 max_range=0.0):\n",
    "\n",
    "        # Initialize\n",
    "        self.save_loc = save_loc\n",
    "        self.distance_threshold_sq = distance_threshold**2\n",
    "        self.score_threshold = min_score\n",
    "        self.max_range = max_range\n",
    "        self.classes = classes\n",
    "        self.total_N_pos = 0\n",
    "        self.results_dict = {}\n",
    "        for single_class in classes:\n",
    "            class_dict = {}\n",
    "            class_dict['class'] = single_class\n",
    "            class_dict['T_p'] = np.empty((0, 8))\n",
    "            class_dict['gt'] = np.empty((0, 7))\n",
    "            class_dict['total_N_pos'] = 0\n",
    "            class_dict['result'] = np.empty((0, 2))\n",
    "            class_dict['precision'] = []\n",
    "            class_dict['recall'] = []\n",
    "            self.results_dict[single_class] = class_dict\n",
    "        # Format\n",
    "        if pred_label_path[-1] is not \"/\":\n",
    "            pred_label_path += \"/\"\n",
    "        if gt_label_path[-1] is not \"/\":\n",
    "            gt_label_path += \"/\"\n",
    "        # Run\n",
    "        self.time = time.time()\n",
    "        self.evaluate(pred_label_path, gt_label_path, label_format)\n",
    "\n",
    "    def evaluate(self, pred_path, gt_path, label_format):\n",
    "        pred_file_list = glob.glob(pred_path + \"*\")\n",
    "        pred_file_list.sort()\n",
    "        gt_file_list = glob.glob(gt_path + \"*\")\n",
    "        gt_file_list.sort()\n",
    "        num_examples = len(pred_file_list)\n",
    "        print(\"Starting evaluation for {} file predictions\".format(num_examples))\n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "        ## Check missing files\n",
    "        print(\"Confirmation prediction ground truth file pairs.\")\n",
    "        for pred_fn in pred_file_list:\n",
    "            if (gt_path + os.path.basename(pred_fn)) not in gt_file_list:\n",
    "                print(\"Error loading labels: gt label for pred label {} was not found.\".format(\n",
    "                    os.path.basename(pred_fn)))\n",
    "                sys.exit(1)\n",
    "\n",
    "        ## Evaluate matches\n",
    "        print(\"Evaluation examples\")\n",
    "        file_parsing = LabelParser(label_format)\n",
    "        for i, pred_fn in enumerate(pred_file_list):\n",
    "            # print(\"\\r\", i+1, \"/\", num_examples, end=\"\")\n",
    "            gt_fn = gt_path + os.path.basename(pred_fn)\n",
    "            predictions = file_parsing.parse_label(pred_fn, prediction=True)\n",
    "            ground_truth = file_parsing.parse_label(gt_fn, prediction=False)\n",
    "        # Filter range\n",
    "            if self.max_range > 0:\n",
    "                predictions, ground_truth = self.filter_by_range(predictions, ground_truth, range=self.max_range)\n",
    "            self.eval_pair(predictions, ground_truth)\n",
    "        print(\"\\nDone!\")\n",
    "        print(\"----------------------------------\")\n",
    "        ## Calculate\n",
    "        for single_class in self.classes:\n",
    "            class_dict = self.results_dict[single_class]\n",
    "            print(\"Calculating metrics for {} class\".format(single_class))\n",
    "            print(\"----------------------------------\")\n",
    "            print(\"Number of ground truth labels: \", class_dict['total_N_pos'])\n",
    "            print(\"Number of detections:  \", class_dict['result'].shape[0])\n",
    "            print(\"Number of true positives:  \", np.sum(class_dict['result'][:, 0] == 1))\n",
    "            print(\"Number of false positives:  \", np.sum(class_dict['result'][:, 0] == 0))\n",
    "            if class_dict['total_N_pos'] == 0:\n",
    "                print(\"No detections for this class!\")\n",
    "                print(\" \")\n",
    "                continue\n",
    "            ## AP\n",
    "            self.compute_ap_curve(class_dict)\n",
    "            mean_ap = self.compute_mean_ap(class_dict['precision'], class_dict['recall'])\n",
    "            print('Mean AP: %.3f ' % mean_ap)\n",
    "            f1 = self.compute_f1_score(class_dict['precision'], class_dict['recall'])\n",
    "            print('F1 Score: %.3f ' % f1)\n",
    "            print(' ')\n",
    "            ## Positive Thresholds\n",
    "            # ATE 2D\n",
    "            ate2d = self.compute_ate2d(class_dict['T_p'], class_dict['gt'])\n",
    "            print('Average 2D Translation Error [m]:  %.4f ' % ate2d)\n",
    "            # ATE 3D\n",
    "            ate3d = self.compute_ate3d(class_dict['T_p'], class_dict['gt'])\n",
    "            print('Average 3D Translation Error [m]:  %.4f ' % ate3d)\n",
    "            # ASE\n",
    "            ase = self.compute_ase(class_dict['T_p'], class_dict['gt'])\n",
    "            print('Average Scale Error:  %.4f ' % ase)\n",
    "            # AOE\n",
    "            aoe = self.compute_aoe(class_dict['T_p'], class_dict['gt'])\n",
    "            print('Average Orientation Error [rad]:  %.4f ' % aoe)\n",
    "            print(\" \")\n",
    "        self.time = float(time.time() - self.time)\n",
    "        print(\"Total evaluation time: %.5f \" % self.time)\n",
    "\n",
    "    def compute_ap_curve(self, class_dict):\n",
    "        t_pos = 0\n",
    "        class_dict['precision'] = np.ones(class_dict['result'].shape[0]+2)\n",
    "        class_dict['recall'] = np.zeros(class_dict['result'].shape[0]+2)\n",
    "        sorted_detections = class_dict['result'][(-class_dict['result'][:, 1]).argsort(), :]\n",
    "        print(sorted_detections.shape)\n",
    "        for i, (result_bool, result_score) in enumerate(sorted_detections):\n",
    "            if result_bool == 1:\n",
    "                t_pos += 1\n",
    "            class_dict['precision'][i+1] = t_pos / (i + 1)\n",
    "            class_dict['recall'][i+1] = t_pos / class_dict['total_N_pos']\n",
    "        class_dict['precision'][i+2] = 0\n",
    "        class_dict['recall'][i+2] = class_dict['recall'][i+1]\n",
    "\n",
    "        ## Plot\n",
    "        plt.figure()\n",
    "        plt.plot(class_dict['recall'], class_dict['precision'])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision Recall curve for {} Class'.format(class_dict['class']))\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.savefig(self.save_loc + class_dict['class'] + \"_pr_curve.png\")\n",
    "\n",
    "    def compute_f1_score(self, precision, recall):\n",
    "        p, r = precision[(precision+recall) > 0], recall[(precision+recall) > 0]\n",
    "        f1_scores = 2 * p * r / (p + r)\n",
    "        return np.max(f1_scores)\n",
    "\n",
    "    def compute_mean_ap(self, precision, recall, precision_threshold=0.0, recall_threshold=0.0):\n",
    "        mean_ap = 0\n",
    "        threshold_mask = np.logical_and(precision > precision_threshold,\n",
    "                                        recall > recall_threshold)\n",
    "        # calculate mean AP\n",
    "        precision = precision[threshold_mask]\n",
    "        recall = recall[threshold_mask]\n",
    "        recall_diff = np.diff(recall)\n",
    "        precision_diff = np.diff(precision)\n",
    "        # Square area under curve based on i+1 precision, then linear difference in precision\n",
    "        mean_ap = np.sum(precision[1:]*recall_diff + recall_diff*precision_diff/2)\n",
    "        # We need to divide by (1-recall_threshold) to make the max possible mAP = 1. In practice threshold by the first\n",
    "        # considered recall value (threshold = 0.1 -> first considered value may be = 0.1123)\n",
    "        mean_ap = mean_ap/(1-recall[0])\n",
    "        return mean_ap\n",
    "\n",
    "    def compute_ate2d(self, predictions, ground_truth):\n",
    "        # euclidean distance 3d\n",
    "        mean_ate2d = np.mean(np.sqrt((predictions[:, 0] - ground_truth[:, 0])**2 +\n",
    "                                     (predictions[:, 1] - ground_truth[:, 1])**2))\n",
    "        return mean_ate2d\n",
    "\n",
    "    def compute_ate3d(self, predictions, ground_truth):\n",
    "        # euclidean distance 2d\n",
    "        mean_ate3d = np.mean(np.sqrt((predictions[:, 0] - ground_truth[:, 0]) ** 2 +\n",
    "                                     (predictions[:, 1] - ground_truth[:, 1]) ** 2 +\n",
    "                                     (predictions[:, 2] - ground_truth[:, 2]) ** 2))\n",
    "        return mean_ate3d\n",
    "\n",
    "    def compute_ase(self, predictions, ground_truth):\n",
    "        # simplified iou where boxes are centered and aligned with eachother\n",
    "        pred_vol = predictions[:, 3:6]\n",
    "        gt_vol = ground_truth[:, 3:6]\n",
    "        iou3d = np.mean(1 - np.prod(np.minimum(pred_vol, gt_vol), axis=1)/np.prod(np.maximum(pred_vol, gt_vol), axis=1))\n",
    "        return iou3d\n",
    "\n",
    "    def compute_aoe(self, predictions, ground_truth):\n",
    "        err = ground_truth[:,6] - predictions[:,6]\n",
    "        aoe = np.mean(np.abs((err + np.pi) % (2*np.pi) - np.pi))\n",
    "        return aoe\n",
    "\n",
    "    def eval_pair(self, pred_label, gt_label):\n",
    "        ## Check\n",
    "        assert pred_label.shape[1] == 9\n",
    "        assert gt_label.shape[1] == 8\n",
    "\n",
    "        ## Threshold score\n",
    "        if pred_label.shape[0] > 0:\n",
    "            pred_label = pred_label[pred_label[:, 8].astype(np.float) > self.score_threshold, :]\n",
    "\n",
    "        for single_class in self.classes:\n",
    "            # get all pred labels, order by score\n",
    "            class_pred_label = pred_label[np.char.lower(pred_label[:, 0].astype(str)) == single_class, 1:]\n",
    "            score = class_pred_label[:, 7].astype(np.float)\n",
    "            class_pred_label = class_pred_label[(-score).argsort(), :].astype(np.float) # sort decreasing\n",
    "\n",
    "            # add gt label length to total_N_pos\n",
    "            class_gt_label = gt_label[np.char.lower(gt_label[:, 0].astype(str)) == single_class, 1:].astype(np.float)\n",
    "            self.results_dict[single_class]['total_N_pos'] += class_gt_label.shape[0]\n",
    "\n",
    "            # match pairs\n",
    "            pred_array, gt_array, result_score_pair = self.match_pairs(class_pred_label, class_gt_label)\n",
    "\n",
    "            # add to existing results\n",
    "            self.results_dict[single_class]['T_p'] = np.vstack((self.results_dict[single_class]['T_p'], pred_array))\n",
    "            self.results_dict[single_class]['gt'] = np.vstack((self.results_dict[single_class]['gt'], gt_array))\n",
    "            self.results_dict[single_class]['result'] = np.vstack((self.results_dict[single_class]['result'],\n",
    "                                                                   result_score_pair))\n",
    "\n",
    "    def match_pairs(self, pred_label, gt_label):\n",
    "        true_preds = np.empty((0, 8))\n",
    "        corresponding_gt = np.empty((0, 7))\n",
    "        result_score = np.empty((0, 2))\n",
    "        # Initialize matching loop\n",
    "        match_incomplete = True\n",
    "        while match_incomplete and gt_label.shape[0] > 0:\n",
    "            match_incomplete = False\n",
    "            for gt_idx, single_gt_label in enumerate(gt_label):\n",
    "                # Check is any prediction is in range\n",
    "                distance_sq_array = (single_gt_label[0] - pred_label[:, 0])**2 + (single_gt_label[1] - pred_label[:, 1])**2\n",
    "                # If there is a prediction in range, pick closest\n",
    "                if np.any(distance_sq_array < self.distance_threshold_sq):\n",
    "                    min_idx = np.argmin(distance_sq_array)\n",
    "                    # Store true prediction\n",
    "                    true_preds = np.vstack((true_preds, pred_label[min_idx, :].reshape(-1, 1).T))\n",
    "                    corresponding_gt = np.vstack((corresponding_gt, gt_label[gt_idx]))\n",
    "\n",
    "                    # Store score for mAP\n",
    "                    result_score = np.vstack((result_score, np.array([[1, pred_label[min_idx, 7]]])))\n",
    "\n",
    "                    # Remove prediction and gt then reset loop\n",
    "                    pred_label = np.delete(pred_label, obj=min_idx, axis=0)\n",
    "                    gt_label = np.delete(gt_label, obj=gt_idx, axis=0)\n",
    "                    match_incomplete = True\n",
    "                    break\n",
    "\n",
    "        # If there were any false detections, add them.\n",
    "        if pred_label.shape[0] > 0:\n",
    "            false_positives = np.zeros((pred_label.shape[0], 2))\n",
    "            false_positives[:, 1] = pred_label[:, 7]\n",
    "            result_score = np.vstack((result_score, false_positives))\n",
    "        return true_preds, corresponding_gt, result_score\n",
    "\n",
    "    def filter_by_range(self, pred_label, gt_label, range=0):\n",
    "        pred_dist = np.linalg.norm(pred_label[:, 1:4].astype(np.float32), axis=1) < range\n",
    "        gt_dist = np.linalg.norm(gt_label[:, 1:4].astype(np.float32), axis=1) < range\n",
    "        return pred_label[pred_dist, :], gt_label[gt_dist, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centerpoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
