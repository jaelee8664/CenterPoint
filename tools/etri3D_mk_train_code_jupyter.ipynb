{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no apex\n",
      "No Tensorflow\n",
      "Deformable Convolution not built!\n",
      "No APEX!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning, NumbaWarning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaWarning)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from det3d.datasets import build_dataset\n",
    "from det3d.models import build_detector\n",
    "from det3d.torchie import Config\n",
    "from det3d.torchie.apis import (\n",
    "    build_optimizer,\n",
    "    get_root_logger,\n",
    "    init_dist,\n",
    "    set_random_seed,\n",
    "    train_detector,\n",
    ")\n",
    "import torch.distributed as dist\n",
    "import subprocess\n",
    "\n",
    "# 주피터 노트북 경로설정\n",
    "os.chdir('../')\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Train a detector\")\n",
    "    parser.add_argument(\"--config\", default=\"configs/etriInfra/pp/etriInfra_centerpoint_pp_02voxel_two_pfn_10sweep.py\", help=\"train config file path\")\n",
    "    parser.add_argument(\"--work_dir\", help=\"the dir to save logs and models\")\n",
    "    parser.add_argument(\"--resume_from\", help=\"the checkpoint file to resume from\")\n",
    "    parser.add_argument(\n",
    "        \"--validate\",\n",
    "        action=\"store_true\",\n",
    "        help=\"whether to evaluate the checkpoint during training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gpus\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"number of gpus to use \" \"(only applicable to non-distributed training)\",\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", type=int, default=None, help=\"random seed\")\n",
    "    parser.add_argument(\n",
    "        \"--launcher\",\n",
    "        choices=[\"pytorch\", \"slurm\"],\n",
    "        default=\"pytorch\",\n",
    "        help=\"job launcher\",\n",
    "    )\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "    parser.add_argument(\n",
    "        \"--autoscale-lr\",\n",
    "        action=\"store_true\",\n",
    "        help=\"automatically scale lr with the number of gpus\",\n",
    "    )\n",
    "    args = parser.parse_args(args=[])\n",
    "    if \"LOCAL_RANK\" not in os.environ:\n",
    "        os.environ[\"LOCAL_RANK\"] = str(args.local_rank)\n",
    "\n",
    "    return args\n",
    "args = parse_args()\n",
    "cfg = Config.fromfile(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution 설정 안함\n",
    "cfg.local_rank = args.local_rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:00,138 - INFO - Distributed training: False\n",
      "2024-04-09 10:20:00,138 - INFO - torch.backends.cudnn.benchmark: False\n"
     ]
    }
   ],
   "source": [
    "# init logger before other steps\n",
    "distributed = False\n",
    "logger = get_root_logger(cfg.log_level)\n",
    "logger.info(\"Distributed training: {}\".format(distributed))\n",
    "logger.info(f\"torch.backends.cudnn.benchmark: {torch.backends.cudnn.benchmark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:00,208 - INFO - Finish RPN Initialization\n",
      "2024-04-09 10:20:00,208 - INFO - num_classes: [2, 2, 1, 1, 2, 1]\n",
      "2024-04-09 10:20:00,225 - INFO - Finish CenterHead Initialization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use HM Bias:  -2.19\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etrInfraDataset'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from det3d.datasets.registry import DATASETS\n",
    "DATASETS\n",
    "cfg.data.train['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registry(name=dataset, items=['ConcatDataset', 'RepeatDataset', 'PointCloudDataset', 'NuScenesDataset', 'WaymoDataset', 'etrInfraDataset'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:04,602 - INFO - {'car': 5, 'personal_mobility': 5, 'truck': 5, 'construction_vehicle': 5, 'bus': 5, 'ground_animal': 5, 'motorcycle': 5, 'bicycle': 5, 'pedestrian': 5}\n",
      "2024-04-09 10:20:04,603 - INFO - [-1]\n",
      "2024-04-09 10:20:05,939 - INFO - load 474176 car database infos\n",
      "2024-04-09 10:20:05,940 - INFO - load 18209 truck database infos\n",
      "2024-04-09 10:20:05,940 - INFO - load 10857 bus database infos\n",
      "2024-04-09 10:20:05,940 - INFO - load 5070 motorcycle database infos\n",
      "2024-04-09 10:20:05,940 - INFO - load 6526 construction_vehicle database infos\n",
      "2024-04-09 10:20:05,941 - INFO - load 28750 pedestrian database infos\n",
      "2024-04-09 10:20:05,941 - INFO - load 11105 personal_mobility database infos\n",
      "2024-04-09 10:20:05,941 - INFO - load 554 bicycle database infos\n",
      "2024-04-09 10:20:05,941 - INFO - load 298 ground_animal database infos\n",
      "2024-04-09 10:20:06,438 - INFO - After filter database:\n",
      "2024-04-09 10:20:06,439 - INFO - load 338483 car database infos\n",
      "2024-04-09 10:20:06,439 - INFO - load 16574 truck database infos\n",
      "2024-04-09 10:20:06,439 - INFO - load 10475 bus database infos\n",
      "2024-04-09 10:20:06,439 - INFO - load 2724 motorcycle database infos\n",
      "2024-04-09 10:20:06,440 - INFO - load 6469 construction_vehicle database infos\n",
      "2024-04-09 10:20:06,440 - INFO - load 23363 pedestrian database infos\n",
      "2024-04-09 10:20:06,440 - INFO - load 7097 personal_mobility database infos\n",
      "2024-04-09 10:20:06,440 - INFO - load 426 bicycle database infos\n",
      "2024-04-09 10:20:06,441 - INFO - load 13 ground_animal database infos\n"
     ]
    }
   ],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.checkpoint_config is not None:\n",
    "    # save det3d version, config file content and class names in\n",
    "    # checkpoints as meta data\n",
    "    cfg.checkpoint_config.meta = dict(\n",
    "        config=cfg.text, CLASSES=datasets[0].CLASSES\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "print(datasets[0].CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from det3d.datasets import DATASETS, build_dataloader\n",
    "# cfg.data.samples_per_gpu: batch_size\n",
    "# cfg.data.workers_per_gpu: workers_per_gpu, num_workers\n",
    "\n",
    "\n",
    "data_loaders = [\n",
    "        build_dataloader(\n",
    "            ds, cfg.data.samples_per_gpu, cfg.data.workers_per_gpu, dist=distributed\n",
    "        )\n",
    "        for ds in datasets\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fbfdd6df5b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:11,911 - INFO - total epochs: 20\n",
      "2024-04-09 10:20:11,912 - INFO -  length of dataloader elems: 6320\n",
      "2024-04-09 10:20:11,913 - INFO - total_steps: 126400\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"total epochs: {cfg.total_epochs}\" )\n",
    "logger.info(f\" length of dataloader elems: {len(data_loaders[0])}\")\n",
    "\n",
    "total_steps = cfg.total_epochs * len(data_loaders[0])\n",
    "logger.info(f\"total_steps: {total_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'one_cycle',\n",
       " 'lr_max': 0.001,\n",
       " 'moms': [0.95, 0.85],\n",
       " 'div_factor': 10.0,\n",
       " 'pct_start': 0.4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.lr_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from det3d.solver.fastai_optim import OptimWrapper\n",
    "from det3d.builder import _create_learning_rate_scheduler\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def flatten_model(m):\n",
    "    return sum(map(flatten_model, m.children()), []) if len(list(m.children())) else [m]\n",
    "\n",
    "def get_layer_groups(m):\n",
    "    return [nn.Sequential(*flatten_model(m))]\n",
    "\n",
    "def build_one_cycle_optimizer(model, optimizer_config):\n",
    "    if optimizer_config.fixed_wd:\n",
    "        optimizer_func = partial(\n",
    "            torch.optim.Adam, betas=(0.9, 0.99), amsgrad=optimizer_config.amsgrad\n",
    "        )\n",
    "\n",
    "\n",
    "    optimizer = OptimWrapper.create(\n",
    "        optimizer_func,\n",
    "        3e-3,   # TODO: CHECKING LR HERE !!!\n",
    "        get_layer_groups(model),\n",
    "        wd=optimizer_config.wd,\n",
    "        true_wd=optimizer_config.fixed_wd,\n",
    "        bn_wd=True,\n",
    "    )\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "if cfg.lr_config.type == \"one_cycle\":\n",
    "    # build trainer\n",
    "    optimizer = build_one_cycle_optimizer(model, cfg.optimizer)\n",
    "    lr_scheduler = _create_learning_rate_scheduler(\n",
    "        optimizer, cfg.lr_config, total_steps\n",
    "    )\n",
    "    cfg.lr_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:12,750 - INFO - model structure: PointPillars(\n",
      "  (reader): PillarFeatureNet(\n",
      "    (pfn_layers): ModuleList(\n",
      "      (0): PFNLayer(\n",
      "        (linear): Linear(in_features=8, out_features=32, bias=False)\n",
      "        (norm): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): PFNLayer(\n",
      "        (linear): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (backbone): PointPillarsScatter()\n",
      "  (neck): RPN(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): ReLU()\n",
      "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (6): ReLU()\n",
      "        (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (9): ReLU()\n",
      "        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (11): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (12): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): ReLU()\n",
      "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (6): ReLU()\n",
      "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (9): ReLU()\n",
      "        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): ReLU()\n",
      "        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (18): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): ReLU()\n",
      "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (6): ReLU()\n",
      "        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (9): ReLU()\n",
      "        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): ReLU()\n",
      "        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (18): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (deblocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bbox_head): CenterHead(\n",
      "    (crit): FastFocalLoss()\n",
      "    (crit_reg): RegLoss()\n",
      "    (shared_conv): Sequential(\n",
      "      (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (tasks): ModuleList(\n",
      "      (0): SepHead(\n",
      "        (reg): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (hm): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): SepHead(\n",
      "        (reg): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (hm): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): SepHead(\n",
      "        (reg): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (hm): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (3): SepHead(\n",
      "        (reg): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (hm): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): SepHead(\n",
      "        (reg): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (hm): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): SepHead(\n",
      "        (reg): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (height): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (dim): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (rot): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (hm): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "logger.info(f\"model structure: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from det3d.torchie.trainer import DistSamplerSeedHook, Trainer, obj_from_dict\n",
    "from collections import OrderedDict\n",
    "\n",
    "def example_to_device(example, device, non_blocking=False) -> dict:\n",
    "    example_torch = {}\n",
    "    float_names = [\"voxels\", \"bev_map\"]\n",
    "    for k, v in example.items():\n",
    "        if k in [\"anchors\", \"anchors_mask\", \"reg_targets\", \"reg_weights\", \"labels\", \"hm\",\n",
    "                \"anno_box\", \"ind\", \"mask\", 'cat', 'points']:\n",
    "            example_torch[k] = [res.to(device, non_blocking=non_blocking) for res in v]\n",
    "        elif k in [\n",
    "            \"voxels\",\n",
    "            \"bev_map\",\n",
    "            \"coordinates\",\n",
    "            \"num_points\",\n",
    "            \"num_voxels\",\n",
    "            \"cyv_voxels\",\n",
    "            \"cyv_num_voxels\",\n",
    "            \"cyv_coordinates\",\n",
    "            \"cyv_num_points\",\n",
    "            \"gt_boxes_and_cls\"\n",
    "        ]:\n",
    "            example_torch[k] = v.to(device, non_blocking=non_blocking)\n",
    "        elif k == \"calib\":\n",
    "            calib = {}\n",
    "            for k1, v1 in v.items():\n",
    "                calib[k1] = v1.to(device, non_blocking=non_blocking)\n",
    "            example_torch[k] = calib\n",
    "        else:\n",
    "            example_torch[k] = v\n",
    "\n",
    "    return example_torch\n",
    "\n",
    "\n",
    "def parse_second_losses(losses):\n",
    "\n",
    "    log_vars = OrderedDict()\n",
    "    loss = sum(losses[\"loss\"])\n",
    "    for loss_name, loss_value in losses.items():\n",
    "        if loss_name == \"loc_loss_elem\":\n",
    "            log_vars[loss_name] = [[i.item() for i in j] for j in loss_value]\n",
    "        else:\n",
    "            log_vars[loss_name] = [i.item() for i in loss_value]\n",
    "\n",
    "    return loss, log_vars\n",
    "\n",
    "def batch_processor(model, data, train_mode, **kwargs):\n",
    "\n",
    "    if \"local_rank\" in kwargs:\n",
    "        device = torch.device(kwargs[\"local_rank\"])\n",
    "    else:\n",
    "        device = None\n",
    "\n",
    "    # data = example_convert_to_torch(data, device=device)\n",
    "    example = example_to_device(data, device, non_blocking=False)\n",
    "\n",
    "    del data\n",
    "\n",
    "    if train_mode:\n",
    "        losses = model(example, return_loss=True)\n",
    "        loss, log_vars = parse_second_losses(losses)\n",
    "\n",
    "        outputs = dict(\n",
    "            loss=loss, log_vars=log_vars, num_samples=len(example[\"anchors\"][0])\n",
    "        )\n",
    "        return outputs\n",
    "    else:\n",
    "        return model(example, return_loss=False)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "        model, batch_processor, optimizer, lr_scheduler, cfg.work_dir, cfg.log_level\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:12,781 - INFO - optimizer_config: {'grad_clip': {'max_norm': 35, 'norm_type': 2}}\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"optimizer_config: {cfg.optimizer_config}\")\n",
    "optimizer_config = cfg.optimizer_config\n",
    "trainer.register_training_hooks(\n",
    "        cfg.lr_config, optimizer_config, cfg.checkpoint_config, cfg.log_config\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainer.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.run(data_loaders, cfg.workflow, cfg.total_epochs, local_rank=cfg.local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:12,815 - INFO - num of dataloader: 1, dataloader type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "2024-04-09 10:20:12,816 - INFO - workflow information: [('train', 1)]\n",
      "2024-04-09 10:20:12,816 - INFO - total_epochs: 20\n",
      "2024-04-09 10:20:12,817 - INFO - local_rank: 0\n"
     ]
    }
   ],
   "source": [
    "# trainer.run 파라미터\n",
    "logger.info(f\"num of dataloader: {len(data_loaders)}, dataloader type: {type(data_loaders[0])}\")\n",
    "logger.info(f\"workflow information: {cfg.workflow}\")\n",
    "logger.info(f\"total_epochs: {cfg.total_epochs}\")\n",
    "logger.info(f\"local_rank: {cfg.local_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_max_epochs = cfg.total_epochs\n",
    "work_dir = '/home/jaelee/objdect/CenterPoint/work_dirs/nusc_centerpoint_voxelnet_0075voxel_fix_bn_z'\n",
    "workflow = cfg.workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:12,853 - INFO - mode: train\n",
      "2024-04-09 10:20:12,854 - INFO - epochs: 1\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "mode, epochs = workflow[idx]\n",
    "logger.info(f\"mode: {mode}\")\n",
    "logger.info(f\"epochs: {epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(data_loaders[idx], epochs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processor_inline(self, model, data, train_mode, **kwargs):\n",
    "\n",
    "    if \"local_rank\" in kwargs:\n",
    "        device = torch.device(kwargs[\"local_rank\"])\n",
    "    else:\n",
    "        device = None\n",
    "\n",
    "    # data = example_convert_to_torch(data, device=device)\n",
    "    example = example_to_device(\n",
    "        data, torch.cuda.current_device(), non_blocking=False\n",
    "    )\n",
    "\n",
    "    self.call_hook(\"after_data_to_device\")\n",
    "\n",
    "    if train_mode:\n",
    "        losses = model(example, return_loss=True)\n",
    "        self.call_hook(\"after_forward\")\n",
    "        loss, log_vars = parse_second_losses(losses)\n",
    "        del losses\n",
    "\n",
    "        outputs = dict(\n",
    "            loss=loss, log_vars=log_vars, num_samples=-1  # TODO: FIX THIS\n",
    "        )\n",
    "        self.call_hook(\"after_parse_loss\")\n",
    "\n",
    "        return outputs\n",
    "    else:\n",
    "        return model(example, return_loss=False)\n",
    "\n",
    "model.train()\n",
    "mode = \"train\"\n",
    "data_loader = data_loaders[idx]\n",
    "length = len(data_loader)\n",
    "_max_iters = _max_epochs * length\n",
    "base_step = epochs * length\n",
    "# outputs = batch_processor_inline(model, data_loader, train_mode=True, local_rank = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fbfdd6df5b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6320"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:20:14,843 - INFO - finding looplift candidates\n"
     ]
    }
   ],
   "source": [
    "ex = data_loader.dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ex['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53542, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['points'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599, 20, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['voxels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8599])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['num_voxels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['num_points'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1, 20, ...,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['num_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([512, 512,   1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['points'][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example = example_to_device(\n",
    "#     data_loader.dataset.__getitem__(0), device, non_blocking=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m example \u001b[38;5;241m=\u001b[39m example_to_device(\n\u001b[1;32m      7\u001b[0m data_batch, device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(example['voxels'][0][0].dtype)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# losses = model(example, return_loss=True)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# loss, log_vars = parse_second_losses(losses)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# del losses\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# outputs = dict(\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#             loss=loss, log_vars=log_vars, num_samples=-1  # TODO: FIX THIS\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#         )\u001b[39;00m\n\u001b[1;32m     16\u001b[0m e \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m s\n",
      "File \u001b[0;32m~/anaconda3/envs/centerpoint/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/objdect/CenterPoint/det3d/models/detectors/point_pillars.py:52\u001b[0m, in \u001b[0;36mPointPillars.forward\u001b[0;34m(self, example, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m preds, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head(x)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_loss:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbbox_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39mpredict(example, preds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_cfg)\n",
      "File \u001b[0;32m~/objdect/CenterPoint/det3d/models/bbox_heads/center_head.py:269\u001b[0m, in \u001b[0;36mCenterHead.loss\u001b[0;34m(self, example, preds_dicts, test_cfg, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m         target_box \u001b[38;5;241m=\u001b[39m target_box[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;66;03m# remove vel target                       \u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[1;32m    271\u001b[0m ret \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# Regression loss for dimension, offset, height, rotation            \u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(0)\n",
    "lst = []\n",
    "for i, data_batch in enumerate(data_loader):\n",
    "    s = time.time()\n",
    "    global_step = base_step + i\n",
    "    example = example_to_device(\n",
    "    data_batch, device, non_blocking=False)\n",
    "    # print(example['voxels'][0][0].dtype)\n",
    "    model(example, return_loss=True)\n",
    "    # losses = model(example, return_loss=True)\n",
    "    # loss, log_vars = parse_second_losses(losses)\n",
    "    # del losses\n",
    "    # outputs = dict(\n",
    "    #             loss=loss, log_vars=log_vars, num_samples=-1  # TODO: FIX THIS\n",
    "    #         )\n",
    "    e = time.time() - s\n",
    "    print(f\"model train time: {e}\")\n",
    "    lst.append(e)\n",
    "    if i == 30:\n",
    "        break\n",
    "lst = lst[1:]\n",
    "avg = sum(lst[1:])/i\n",
    "print(f\"{i} samples avg train time: {sum(lst)/(i+1)}\")\n",
    "var = sum((np.array(lst) - avg)**2)/i\n",
    "print(f\"{i} samples var: {var}\")\n",
    "print(f\"max: {max(lst)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centerpoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
